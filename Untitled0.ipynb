{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvdov2GXYrq2auTNRd5+xc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjdudgml3/graduate_prj/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlKV-Qd2OOrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f8d5bb-d14d-48d1-bce7-1e5b30fad80f"
      },
      "source": [
        "\"\"\"project_1.ipynb의 사본\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/14Xgbqbr8oqDhSZu8ZxbKljLQ7fyUVYID\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os \n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import cv2\n",
        "import multiprocessing\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 사용할 수 있는 cpu 갯수 \n",
        "cpu = multiprocessing.cpu_count() \n",
        "print(\"cpu_count :\", cpu)\n",
        "\n",
        "# 파일에 들어있는 이미지 갯수 확인하기 \n",
        "os.chdir('/content/gdrive/MyDrive/graduate_prj/projectimg')\n",
        "file_name = os.listdir()\n",
        "cwd = os.getcwd()\n",
        "\n",
        "img_path = [] \n",
        "for i in range(len(file_name)):\n",
        "  path = os.path.join(cwd, file_name[i])\n",
        "  print(file_name[i],\":\",len(os.listdir(path)))\n",
        "  # 파일에 들어있는 이미지의 경로를 리스트 형태로 구현 \n",
        "  img_path.append(list(glob.glob(os.path.join(path,\"*\"))))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "cpu_count : 2\n",
            "Food : 16\n",
            "Person : 16\n",
            "Kakao-talk : 21\n",
            "Game : 21\n",
            "Pet : 14\n",
            "Unknown : 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3No3597kQE3",
        "outputId": "327da748-42f2-442b-8937-976579651f2f"
      },
      "source": [
        "def split(List):\n",
        "  # shuffle\n",
        "  random.shuffle(List)  \n",
        "\n",
        "  # train data : test data = 8 : 2\n",
        "  split_ratio = int(len(List) * 0.2)\n",
        "  test_set = List[ :split_ratio]\n",
        "  train_set = List[split_ratio: ]\n",
        "  return train_set, test_set\n",
        "\n",
        "# 0-game, 1-cat, 2-dof, 3-kakaotalk, 4-food, 5-person\n",
        "# img_path[0] ~ img_path[5]: 각 파일에 있는 이미지경로 \n",
        "train_x, train_y, test_x, test_y = [], [], [], []\n",
        "for i in range(len(img_path)):  \n",
        "   train, test = split(img_path[i])\n",
        "   print(file_name[i],\"- train_set:\",len(train),\", test_set\",len(test))\n",
        "\n",
        "   train_x += train\n",
        "   test_x += test\n",
        "   \n",
        "   train_y += ([i] * len(train))\n",
        "   test_y += ([i] * len(test))\n",
        "\n",
        "print(len(img_path[1]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Food - train_set: 13 , test_set 3\n",
            "Person - train_set: 13 , test_set 3\n",
            "Kakao-talk - train_set: 17 , test_set 4\n",
            "Game - train_set: 17 , test_set 4\n",
            "Pet - train_set: 12 , test_set 2\n",
            "Unknown - train_set: 17 , test_set 4\n",
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-FHVcxKcqj-",
        "outputId": "ca81ac5e-eed7-444c-8bcd-b1d3d81bfff5"
      },
      "source": [
        "len(train_x)\n",
        "print(train_x[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/graduate_prj/projectimg/Food/칼바람 (12).jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H9ejqvP5Ya8",
        "outputId": "d818f301-9f44-4129-9a91-cdac276665b7"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "class BasicBlock(layers.Layer):\n",
        "    def __init__(self, filter_num, stride=1):\n",
        "        \"\"\"\n",
        "                 : param filter_num: Number of conjunctions\n",
        "                 : Param Stride: Steps\n",
        "        \"\"\"\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # Ceramic layer 1 may be sampled\n",
        "        self.conv1 = layers.Conv2D(filter_num, (3, 3),\n",
        "                                   strides=stride, padding=\"same\")\n",
        "        self.bn1 = layers.BatchNormalization()\n",
        "        self.relu = layers.Activation(\"relu\")\n",
        "\n",
        "        #     2 does not make a sample\n",
        "        self.conv2 = layers.Conv2D(filter_num, (3, 3),\n",
        "                                   strides=1, padding=\"same\")\n",
        "        self.bn2 = layers.BatchNormalization()\n",
        "\n",
        "        if stride != 1:  # Whether to use the sample\n",
        "            #    \n",
        "            self.down_sample = tf.keras.models.Sequential()\n",
        "            # May make sampling\n",
        "            self.down_sample.add(layers.Conv2D(filter_num, (1, 1), strides=stride))\n",
        "            self.down_sample.add(layers.BatchNormalization())\n",
        "        else:\n",
        "            # Don't make a sample\n",
        "            self.down_sample = lambda x: x\n",
        "\n",
        "        self.stride = stride  #  \n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # Residual edge according to Stride (sample or not processed)\n",
        "        identity = self.down_sample(inputs)\n",
        "\n",
        "        #      \n",
        "        #   1 Convolution + Regularization + RELU Layer\n",
        "        out = self.conv1(inputs)  # According to Stride (down sample or do not process)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        #   2 Convolution + Regularization\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        #       + residual edge\n",
        "        out_put = layers.add([out, identity])\n",
        "        # RELU function\n",
        "        out_put = tf.nn.relu(out_put)\n",
        "\n",
        "        return out_put\n",
        "\n",
        "\n",
        "# Rsnet network creation\n",
        "class ResNet(tf.keras.Model):\n",
        "    def __init__(self, layer_dims, num_classes=100):  # [2, 2, 2, 2]\n",
        "        # LAYER_DIMS layer dimensions 18: [2 * res_block, 2 * res_block, 2 * res_block, 2 * res_block]\n",
        "        # 34:[3, 4, 6, 3]\n",
        "        super(ResNet, self).__init__()\n",
        "        self.stem = tf.keras.models.Sequential([layers.Conv2D(64, (3, 3), strides=(1, 1)),\n",
        "                                layers.BatchNormalization(),\n",
        "                                layers.Activation(\"relu\"),\n",
        "                                layers.MaxPool2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\")\n",
        "                                ])\n",
        "        # 2 Block\n",
        "        self.layer1 = self.build_res_block(64, layer_dims[0])\n",
        "        # 2 blocks Sampling\n",
        "        self.layer2 = self.build_res_block(128, layer_dims[1], stride=2)\n",
        "        # 2 blocks Sampling\n",
        "        self.layer3 = self.build_res_block(256, layer_dims[2], stride=2)\n",
        "        # 2 blocks Sampling\n",
        "        self.layer4 = self.build_res_block(512, layer_dims[3], stride=2)\n",
        "\n",
        "        # Output: [B, 512, H, W] ==> Global mean pool\n",
        "        self.avg_pool = layers.GlobalAveragePooling2D()\n",
        "        #      \n",
        "        self.fc = layers.Dense(num_classes)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        #      \n",
        "        # Preliminary treatment\n",
        "        x = self.stem(inputs)\n",
        "        # Four layers of superposition\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        # [b, c] global mean poolization\n",
        "        x = self.avg_pool(x)\n",
        "        # [b, 100] full connection layer\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    # Basic Unit Block\n",
        "    @staticmethod\n",
        "    def build_res_block(filter_num, blocks, stride=1):\n",
        "        res_blocks = tf.keras.models.Sequential()\n",
        "\n",
        "        #      \n",
        "        res_blocks.add(BasicBlock(filter_num, stride))\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            # Don't make a sample\n",
        "            res_blocks.add(BasicBlock(filter_num, stride=1))\n",
        "        return res_blocks\n",
        "\n",
        "\n",
        "# Resnet 18 floor\n",
        "def resnet18():\n",
        "    return ResNet([2, 2, 2, 2])\n",
        "\n",
        "\n",
        "# Resnet 34\n",
        "def resnet34():\n",
        "    return ResNet([3, 4, 6, 3])\n",
        "\n",
        "model = resnet18()\n",
        "model.build(input_shape=(None,224,224, 3))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"res_net\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential (Sequential)      (None, 222, 222, 64)      2048      \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 222, 222, 64)      148736    \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 111, 111, 128)     527488    \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 56, 56, 256)       2103552   \n",
            "_________________________________________________________________\n",
            "sequential_6 (Sequential)    (None, 28, 28, 512)       8401408   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  51300     \n",
            "=================================================================\n",
            "Total params: 11,234,532\n",
            "Trainable params: 11,224,932\n",
            "Non-trainable params: 9,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naeweUrGkWRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e35180-d19e-406c-cc7b-056053d14740"
      },
      "source": [
        "# # 팀원이 구현할 모델로 대체 예정 \n",
        "# model = tf.keras.Sequential([      \n",
        "#   layers.Conv2D(32, 3, activation='relu', padding='same', input_shape=(224,224,3)),\n",
        "#   layers.MaxPooling2D(),\n",
        "#   layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "#   layers.MaxPooling2D(),\n",
        "#   layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "#   layers.MaxPooling2D(),\n",
        "#   layers.Flatten(),\n",
        "#   layers.Dense(128, activation='relu'),\n",
        "#   layers.Dense(6, activation='softmax')\n",
        "# ])\n",
        "\n",
        "\n",
        "# loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "# model.summary()\n",
        "\n",
        "def convA(x):\n",
        "  # x = tf.keras.layers.ZeroPadding2D(padding = (3,3))(x)\n",
        "  x = tf.keras.layers.Conv2D( 64, (7,7),strides = (2,2),padding = 'same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x=  tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.ZeroPadding2D(padding = (1,1))(x)\n",
        "  x = tf.keras.layers.MaxPool2D((3,3),(2,2),padding ='same')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def convB(x):\n",
        "  shortcut = x\n",
        "  # print(f\"shortcut.shape = {shortcut.shape}\")\n",
        "  # print(f\"x shape = {x.shape}\") \n",
        "  x = tf.keras.layers.Conv2D(64,(3,3),strides = (1,1),padding = 'same')(x)\n",
        "  # print(f\"shortcut1.shape = {shortcut.shape}\")\n",
        "  # print(f\"x shape1 = {x.shape}\") \n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  # print(f\"shortcut1.shape = {shortcut.shape}\")\n",
        "  # print(f\"x shape1 = {x.shape}\") \n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(64,(3,3),strides = (1,1),padding = 'same')(x)\n",
        "  # print(f\"shortcut1.shape = {shortcut.shape}\")\n",
        "  # print(f\"x shape1 = {x.shape}\") \n",
        "  \n",
        "  # shortcut = tf.keras.layers.Conv2D(64,(1,1),strides = (1,1), padding = 'valid')(shortcut)\n",
        "  # x = tf.keras.layers.BatchNormalization()(x)\n",
        "  # shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
        "  # print(f\"shortcut1.shape = {shortcut.shape}\")\n",
        "  # print(f\"x shape1 = {x.shape}\")  \n",
        "  x = tf.keras.layers.Add()([x,shortcut])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  \n",
        "  shortcut = x\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(64,(3,3),strides = (1,1),padding ='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(64,(3,3),strides = (1,1),padding='same')(x)\n",
        "  # shortcut = tf.keras.layers.Conv2D(64,(1,1),strides = (1,1), padding = 'valid')(shortcut)\n",
        "  # shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  # print(f\"shortcut.shape2 = {shortcut.shape}\")\n",
        "  # print(f\"x shape2 = {x.shape}\")\n",
        "  x = tf.keras.layers.Add()([x,shortcut])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  # print(f\"shortcut.shape2 = {shortcut.shape}\")\n",
        "  # print(f\"x shape2 = {x.shape}\")\n",
        "\n",
        "  return x\n",
        "\n",
        "def convC(x):\n",
        "  shortcut = x\n",
        "  x = tf.keras.layers.Conv2D(128,(3,3),strides = (1,1),padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(128,(3,3),strides = (1,1),padding='same')(x)\n",
        "  shortcut = tf.keras.layers.Conv2D(128,(1,1),strides = (1,1), padding = 'valid')(shortcut)\n",
        "  shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Add()([x,shortcut])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  shortcut = x\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(128,(3,3),strides = (1,1),padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(128,(3,3),strides = (1,1),padding='same')(x)\n",
        "  # shortcut = tf.keras.layers.Conv2D(128,(1,1),strides = (1,1), padding = 'valid')(shortcut)\n",
        "  # shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Add()([x,shortcut])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  return x\n",
        "\n",
        "def convD(x):\n",
        "  shortcut = x\n",
        "  x = tf.keras.layers.Conv2D( 256,(3,3),strides = (1,1),padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(256,(3,3),strides = (1,1),padding='same')(x)\n",
        "  shortcut = tf.keras.layers.Conv2D(256,(1,1),strides = (1,1), padding = 'valid')(shortcut)\n",
        "  shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Add()([x,shortcut])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  shortcut = x\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(256,(3,3),strides = (1,1),padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.Conv2D(256,(3,3),strides = (1,1),padding='same')(x)\n",
        "  # shortcut = tf.keras.layers.Conv2D(256,(1,1),strides = (1,1), padding = 'valid')(shortcut)\n",
        "  # shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Add()([x,shortcut])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  return x\n",
        "\n",
        "def convE(x):\n",
        "  shortcut = x\n",
        "  x = tf.keras.layers.Conv2D(512,(3,3),strides = (1,1),padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.Conv2D( 512,(3,3),strides = (1,1),padding='same')(x)\n",
        "  shortcut = tf.keras.layers.Conv2D(512,(1,1),strides = (1,1), padding = 'valid')(shortcut)\n",
        "  shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Add()([x,shortcut])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  shortcut = x\n",
        "\n",
        "  x = tf.keras.layers.Conv2D( 512,(3,3),strides = (1,1),padding='same')(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.Conv2D( 512,(3,3),strides = (1,1),padding='same')(x)\n",
        "  # shortcut = tf.keras.layers.Conv2D(512,(1,1),strides = (1,1), padding = 'valid')(shortcut)\n",
        "  # shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Add()([x,shortcut])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  return x\n",
        "\n",
        "input = tf.keras.layers.Input(shape=(224, 224, 3), dtype='float32', name='input')\n",
        "x = convA(input)\n",
        "x = convB(x)\n",
        "x = convC(x)\n",
        "x = convD(x)\n",
        "x = convE(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "output = tf.keras.layers.Dense(4,activation= 'softmax')(x)\n",
        "model = tf.keras.Model(input,output)\n",
        "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 112, 112, 64) 9472        input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 112, 112, 64) 256         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 112, 112, 64) 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 114, 114, 64) 0           activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 57, 57, 64)   0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 57, 57, 64)   36928       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 57, 57, 64)   256         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 57, 57, 64)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 57, 57, 64)   36928       activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 57, 57, 64)   0           conv2d_62[0][0]                  \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 57, 57, 64)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 57, 57, 64)   36928       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 57, 57, 64)   256         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 57, 57, 64)   0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 57, 57, 64)   36928       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 57, 57, 64)   256         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 57, 57, 64)   0           batch_normalization_61[0][0]     \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 57, 57, 64)   0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 57, 57, 128)  73856       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 57, 57, 128)  512         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 57, 57, 128)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 57, 57, 128)  147584      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 57, 57, 128)  8320        activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 57, 57, 128)  512         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 57, 57, 128)  512         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 57, 57, 128)  0           batch_normalization_64[0][0]     \n",
            "                                                                 batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 57, 57, 128)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 57, 57, 128)  147584      activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 57, 57, 128)  512         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 57, 57, 128)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 57, 57, 128)  147584      activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 57, 57, 128)  512         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 57, 57, 128)  0           batch_normalization_66[0][0]     \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 57, 57, 128)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 57, 57, 256)  295168      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 57, 57, 256)  1024        conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 57, 57, 256)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 57, 57, 256)  590080      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 57, 57, 256)  33024       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 57, 57, 256)  1024        conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 57, 57, 256)  1024        conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 57, 57, 256)  0           batch_normalization_69[0][0]     \n",
            "                                                                 batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 57, 57, 256)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 57, 57, 256)  590080      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 57, 57, 256)  1024        conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 57, 57, 256)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 57, 57, 256)  590080      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 57, 57, 256)  1024        conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, 57, 57, 256)  0           batch_normalization_71[0][0]     \n",
            "                                                                 activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 57, 57, 256)  0           add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 57, 57, 512)  1180160     activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 57, 57, 512)  2048        conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 57, 57, 512)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 57, 57, 512)  2359808     activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 57, 57, 512)  131584      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 57, 57, 512)  2048        conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 57, 57, 512)  2048        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 57, 57, 512)  0           batch_normalization_74[0][0]     \n",
            "                                                                 batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 57, 57, 512)  0           add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 57, 57, 512)  2359808     activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 57, 57, 512)  2048        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 57, 57, 512)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 57, 57, 512)  2359808     activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 57, 57, 512)  2048        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 57, 57, 512)  0           batch_normalization_76[0][0]     \n",
            "                                                                 activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 57, 57, 512)  0           add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 512)          0           activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 512)          0           global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4)            2052        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 11,192,708\n",
            "Trainable params: 11,183,236\n",
            "Non-trainable params: 9,472\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-4I5XB3x2ur"
      },
      "source": [
        "# class IdentityBlock(tf.keras.Model):\n",
        "#   def __init__(self, filters, kernel_size):\n",
        "#     super(IdentityBlock, self).__init__(name='')\n",
        "#     self.conv1 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "#     self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "#     self.conv2 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
        "#     self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "#     self.relu = tf.keras.layers.Activation('relu')\n",
        "#     self.add = tf.keras.layers.Add()\n",
        "#   def call(self, inputs):\n",
        "#     x = self.conv1(inputs)\n",
        "#     x = self.bn1(x)\n",
        "#     x = self.relu(x)\n",
        "#     x = self.conv2(x)\n",
        "#     x = self.bn2(x)\n",
        "#     x = self.add([x, inputs])\n",
        "#     x = self.relu(x)\n",
        "#     return x\n",
        "\n",
        "# class ResNet(tf.keras.Model):\n",
        "#   def __init__(self, num_classes):\n",
        "#     super(ResNet, self).__init__()\n",
        "#     self.conv = tf.keras.layers.Conv2D(64, 7, padding='same')\n",
        "#     self.bn = tf.keras.layers.BatchNormalization()\n",
        "#     self.relu = tf.keras.layers.Activation('relu')\n",
        "#     self.max_pool = tf.keras.layers.MaxPool2D((3, 3))\n",
        "#     self.id1a = IdentityBlock(64, 3)\n",
        "#     self.id1b = IdentityBlock(64, 3)\n",
        "#     self.global_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "#     self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "#   def call(self, inputs):\n",
        "#     x = self.conv(inputs)\n",
        "#     x = self.bn(x)\n",
        "#     x = self.relu(x)\n",
        "#     x = self.max_pool(x)\n",
        "#     x = self.id1a(x)\n",
        "#     x = self.id1b(x)\n",
        "#     x = self.global_pool(x)\n",
        "#     return self.classifier(x)\n",
        "\n",
        "# model = ResNet(10)\n",
        "# model.build((None,224,224,3))\n",
        "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
        "# model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "NonOd-hOab3L",
        "outputId": "8e9d4b4e-f3d5-4723-db32-1a72c7acdbbe"
      },
      "source": [
        "model = tf.keras.applications.resnet50.ResNet50(include_top=True, weights=None, input_tensor=None,input_shape=(224,224,3), pooling=max, classes=5)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8b241b2807b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResNet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.applications' has no attribute 'resnet18'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dvndOV6kaNl",
        "outputId": "2866bd35-0574-4d56-8e0c-e16bb7a435b5"
      },
      "source": [
        "li = [1,2,3,4]\n",
        "li.append(100)\n",
        "print(li)\n",
        "\n",
        "def preprocess(r):\n",
        "    img = cv2.imread(r)\n",
        "    if img is None:\n",
        "      print(r)\n",
        "      pass\n",
        "    else:\n",
        "      img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA) \n",
        "      img = img.astype(np.float32) / 255.  \n",
        "      return img\n",
        "# for i in range(len(train_x)):\n",
        "#   img = cv2.imread(train_x[i])\n",
        "#   if img is None:\n",
        "#       print(train_x[i])\n",
        "#       pass\n",
        "#   else:\n",
        "#     img = cv2.resize(img,(224,224),interpolation = cv2.INTER_AREA)\n",
        "#     img = img.astype(np.float32)/255.\n",
        "#     train_x[i] = img\n",
        "  \n",
        "# for i in range(len(test_x)):\n",
        "#   img = cv2.imread(test_x[i])\n",
        "#   if img is None:\n",
        "#       print(test_x[i])\n",
        "#       pass\n",
        "#   else:\n",
        "#     img = cv2.resize(img,(224,224),interpolation = cv2.INTER_AREA)\n",
        "#     img = img.astype(np.float32)/255.\n",
        "#     train_x[i] = img\n",
        "# train_y = np.array(train_y)\n",
        "# test_y = np.array(test_y)\n",
        "# pool = multiprocessing.Pool(processes=cpu)\n",
        "# train_x = np.array(pool.map(preprocess,train_x))\n",
        "# train_y = np.array(train_y)\n",
        "# test_x = np.array(pool.map(preprocess,test_x))\n",
        "# test_y = np.array(test_y)\n",
        "# pool.close()\n",
        "# pool.join()\n",
        "epoch= 1\n",
        "batch_size = 100\n",
        "slice_num = 0\n",
        "\n",
        "# history = model.fit(train_x,train_y,epochs = 5, batch_size =1 , validation_data = (test_x,test_y) )\n",
        "\n",
        "# model.compile()\n",
        "\n",
        "# 배치사이즈로 나눠서 train하는 과정 \n",
        "# 속도개선을 위한 멀티프로세스 사용, 2개로 병렬처리\n",
        "# 한 배치에 150 \n",
        "for i in range(round(len(train_x) / batch_size)):\n",
        "   # batchx_new, batchy_new = [], []\n",
        "   batch_x = train_x[0+slice_num : batch_size+slice_num]\n",
        "   batch_y = train_y[0+slice_num : batch_size+slice_num]\n",
        "   slice_num += batch_size     \n",
        "\n",
        "   pool = multiprocessing.Pool(processes=cpu)\n",
        "   batch_x = np.array(pool.map(preprocess,batch_x))\n",
        "   batch_y = np.array(batch_y)\n",
        "   pool.close()\n",
        "   pool.join() \n",
        "   \n",
        "   with tf.GradientTape() as tape:\n",
        "      logits = model(batch_x)\n",
        "      print(\"예측값_softmax:\",np.argmax(logits, axis=1))\n",
        "      print(\"________________________________________\")  \n",
        "      print(\"실제값:\",batch_y)\n",
        "      loss_value = loss_func(batch_y, logits)\n",
        "\n",
        "   gradients = tape.gradient(loss_value, model.trainable_variables)\n",
        "   optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "   print(i,\"-loss_value:\",loss_value)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 100]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynxSyiq0kfsJ"
      },
      "source": [
        "batch_y = []\n",
        "random.shuffle(batch_x)\n",
        "for i in batch_x:\n",
        "    dir,_ = os.path.split(i)\n",
        "    if dir == '/content/gdrive/MyDrive/projectimg/Pet': batch_y.append(0)\n",
        "    elif dir == '/content/gdrive/MyDrive/projectimg/Person': batch_y.append(2)\n",
        "    elif dir == '/content/gdrive/MyDrive/projectimg/Kakao-talk': batch_y.append(3)\n",
        "    elif dir == '/content/gdrive/MyDrive/projectimg/Game': batch_y.append(4)\n",
        "    elif dir == '/content/gdrive/MyDrive/projectimg/Food': batch_y.append(5)\n",
        "\n",
        "epoch= 1\n",
        "batch_size = 100\n",
        "slice_num = 0\n",
        "for i in range(round(len(test_x) / batch_size)):\n",
        "   # batchx_new, batchy_new = [], []\n",
        "   batch_testx = test_x[0+slice_num : batch_size+slice_num]\n",
        "   batch_testy = test_y[0+slice_num : batch_size+slice_num]\n",
        "   slice_num += batch_size     \n",
        "\n",
        "   pool = multiprocessing.Pool(processes=cpu)\n",
        "   batch_testx = np.array(pool.map(preprocess,batch_testx))\n",
        "   batch_testy = np.array(batch_testy)\n",
        "   pool.close()\n",
        "   pool.join() \n",
        "\n",
        "   with tf.GradientTape() as tape:\n",
        "      logits = model(batch_testx)  \n",
        "      loss_value = loss_func(batch_testy, logits)\n",
        "\n",
        "   print(i,\":\",loss_value)\n",
        "\n",
        "\n",
        "\n",
        "# 카톡 캡처본이랑 게임 캡처본을 제외한, 나머지 이미지들에 대해서 데이터 어그멘테이션 적용 \n",
        "\n",
        " # 1. Rotation \n",
        "def rotation(img):\n",
        "    h,w = img.shape[:2] \n",
        "    center = (int(w/2), int(h/2)) \n",
        "    move = cv2.getRotationMatrix2D(center, np.random.randint(-30,30), 1.0)\n",
        "    img = cv2.warpAffine(img,move,(w,h))\n",
        "    return img\n",
        "\n",
        "# 2. Flip \n",
        "def flip(img):\n",
        "    # -1:상하좌우, 0:상하, 1:좌우\n",
        "    #case = np.random.randint(-1,1+1) \n",
        "    img = cv2.flip(img, 1)\n",
        "    return img\n",
        "\n",
        "# 3. Zoom \n",
        "def zoom(img):\n",
        "    h,w = img.shape[:2] \n",
        "    n = np.random.uniform(0.5, 1, 1)\n",
        "    # 확대할 부분의 시작 x좌표:w_start, y좌표:h_start \n",
        "    # 확대할 부분의 높이:n*h, 너비:n*w \n",
        "    h_start = np.random.randint(0, h - int(n*h))\n",
        "    w_start = np.random.randint(0, w - int(n*w))\n",
        "     \n",
        "    img = img[h_start : h_start+int(n*h), w_start : w_start+int(n*w), ]\n",
        "    img = cv2.resize(img, (h, w), cv2.INTER_CUBIC)\n",
        "    return img \n",
        "\n",
        "# 4. Brightness \n",
        "def brightness(img):\n",
        "    case = np.random.randint(1,2+1)\n",
        "    v = np.random.choice(range(30,50+10,10))\n",
        "    init = np.ones(img.shape, dtype = 'uint8') \n",
        "    \n",
        "    if case == 1:\n",
        "      img = cv2.add(img, init * v)\n",
        "    else: \n",
        "      img = cv2.subtract(img, init * v)\n",
        "    return img\n",
        "\n",
        "# 5. Move  \n",
        "def move(img):\n",
        "    h,w = img.shape[:2] \n",
        "    dx, dy = np.random.randint(-np.min([h,w]) // 2, np.min([h,w]) // 2, 2)\n",
        "    mat = np.array([[1, 0, dx], [0, 1, dy]], dtype = np.float32)\n",
        "    img = cv2.warpAffine(img, mat, (w+dx, h+dy))\n",
        "    return img\n",
        "    \n",
        "# 6. Gaussian noise \n",
        "def Gaussian_noise(img):   \n",
        "    g = np.random.normal(0, 1, img.shape)\n",
        "    img = cv2.add(img, g.astype('uint8'))\n",
        "    return img\n",
        "\n",
        "# 7. 1) GaussianBlur, 2) medianBlur \n",
        "def blur(img):\n",
        "    case = np.random.randint(1,2+1)\n",
        "    k_size = 3\n",
        "    if case == 1: \n",
        "        img = cv2.GaussianBlur(img, (k_size, k_size), 0)\n",
        "    else: \n",
        "        img = cv2.medianBlur(img, k_size)\n",
        "    return img\n",
        "\n",
        "'''\n",
        "  # 8. clahe\n",
        "  def clahe(self,img):\n",
        "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    c = cv2.createCLAHE(clipLimit=40, tileGridSize=(8,8))\n",
        "    img_hsv[:,:,2] = c.apply(img_hsv[:,:,2])\n",
        "    img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
        "    return img\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}